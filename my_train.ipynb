{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CONNECT WITH DRIVE\n",
    "\"\"\"\n",
    "\n",
    "%pip install gdown\n",
    "import gdown\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1IrhQFVlV8aIQ9EV4J-pHhCR1tNk3noTN'\n",
    "output = '/data/dataset_nonrandom_responses.pth'\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CorrVAE training based on [TODO]\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "\n",
    "from model import ControlVAE\n",
    "from encoders import EncoderControlVAE\n",
    "from decoders import DecoderControlVAE\n",
    "\n",
    "from utils.helpers import prepare_dataloader, plot_epoch, save_model\n",
    "from utils.loss import get_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ARGUMENTS\n",
    "\"\"\"\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "results_dir = '/content/drive/MyDrive/models/'\n",
    "data_source = 'dataset_nonrandom_responses.pth'\n",
    "\n",
    "img_size = (1, 44, 44)\n",
    "latent_dim = 8\n",
    "num_prop = 3\n",
    "lr = 1e-4\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "beta = 1\n",
    "taus = 0.2\n",
    "idx_kl = 0\n",
    "w_kl = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WANDB LOGGER\n",
    "\"\"\"\n",
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    %pip install wandb\n",
    "    import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"CorrVAE_64x64\",\n",
    "\n",
    "    config={\n",
    "        # \"data size\": train_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"beta\": beta,\n",
    "        \"taus\": taus,\n",
    "        \"loss func\": 'sigmoid',\n",
    "        \"lr\": lr,\n",
    "        \"num prop\": num_prop,\n",
    "        \"latent_dim\": latent_dim,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA\n",
    "\"\"\"\n",
    "\n",
    "data = torch.load(data_source)\n",
    "dataset = TensorDataset(data['features'], data['labels'])\n",
    "\n",
    "train_loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL\n",
    "\"\"\"\n",
    "\n",
    "encoder = eval(\"EncoderControlVAE\")\n",
    "decoder = eval(\"DecoderControlVAE\")\n",
    "\n",
    "model = ControlVAE(img_size, encoder, decoder, latent_dim, num_prop, device=device)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[10, 20, 30, 50, 70, 100, 130, 160, 200],\n",
    "        gamma=0.1\n",
    ")\n",
    "\n",
    "mse_loss = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "recon_loss_prop_rec = []\n",
    "recon_loss_rec = []\n",
    "kl_loss_rec = []\n",
    "pwwi_loss_rec = []\n",
    "pwz_loss_rec = []\n",
    "l1_loss_rec = []\n",
    "mask_rec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        taus = taus * 0.1\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_kl_loss = []\n",
    "    epoch_rec_loss = []\n",
    "    epoch_prop_loss = []\n",
    "    epoch_pairwise_loss = []\n",
    "    epoch_groupwise_loss = []\n",
    "    epoch_l1_norm = []\n",
    "    \n",
    "    for (data, label) in tqdm(train_loader):\n",
    "        idx_kl += 1\n",
    "        data = data.to(device)\n",
    "        \n",
    "        (reconstruct,y_reconstruct), latent_dist_z, latent_dist_w,\\\n",
    "            latent_sample_z, latent_sample_w, w_mask, mask_ori = model(data, taus)\n",
    "\n",
    "        latent_sample = torch.cat([latent_sample_w, latent_sample_z], dim=-1)\n",
    "        latent_dist = (torch.cat([latent_dist_w[0], latent_dist_z[0]], dim=-1), \n",
    "                       torch.cat([latent_dist_w[1], latent_dist_z[1]], dim=-1))\n",
    "        \n",
    "        ###### Reconstruction loss ######\n",
    "        rec_loss = F.mse_loss(reconstruct, data, reduction=\"sum\") / 64\n",
    "        rec_loss = rec_loss / batch_size\n",
    "        \n",
    "        rec_loss_prop = []\n",
    "        rec_loss_prop.append(mse_loss(y_reconstruct[:,0], label[:,0].float().to(device)))\n",
    "        rec_loss_prop.append(mse_loss(y_reconstruct[:,1], label[:,1].float().to(device)))\n",
    "        # rec_loss_prop.append(mse_loss(y_reconstruct[:,2], label[:,2].float().to(device)))\n",
    "        rec_loss_prop_all = sum(rec_loss_prop)\n",
    "        \n",
    "        ###### Other losses ######\n",
    "        kl_loss, pairwise_tc_loss, groupwise_tc_loss, l1norm, loss, w_kl = get_losses(\n",
    "            latent_dist, latent_sample_w, latent_dist_w, beta,\n",
    "            latent_sample_z, latent_dist_z, w_mask, device, idx_kl,\n",
    "            rec_loss, rec_loss_prop_all, w_kl, len(train_loader.dataset)\n",
    "        )\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(float(loss))\n",
    "        epoch_kl_loss.append(float(kl_loss))\n",
    "        epoch_rec_loss.append(float(rec_loss))\n",
    "        epoch_prop_loss.append(float(rec_loss_prop_all))\n",
    "        epoch_pairwise_loss.append(float(pairwise_tc_loss))\n",
    "        epoch_groupwise_loss.append(float(groupwise_tc_loss))\n",
    "        epoch_l1_norm.append(float(l1norm))\n",
    "\n",
    "    wandb.log(\n",
    "        {\"total_loss \": np.mean(epoch_loss),\n",
    "            \"KL_loss\": np.mean(epoch_kl_loss),\n",
    "            \"rec_loss\": np.mean(epoch_rec_loss),\n",
    "            \"rec_prop_loss\": np.mean(epoch_prop_loss),\n",
    "            \"wwi_loss\": np.mean(epoch_pairwise_loss),\n",
    "            \"wz_loss\": np.mean(epoch_groupwise_loss),\n",
    "            \"l1_norm\": np.mean(epoch_l1_norm),\n",
    "    })\n",
    "\n",
    "    save_model(model, optimizer, results_dir, epoch)\n",
    "    plot_epoch(train_loader, model, device, taus, epoch, time.time() - start_epoch)\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    start_epoch = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75a7a2f2856d09d3581c769256ac1c015132059993c94c4aebdcd920fc505d70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
