{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW3EIvBP8e7b",
        "outputId": "1c1b8ca6-c695-4731-cfde-2c6cacb3fdba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ay6j3rMwSq2qqBSCqC125tFG0c9MEXwW\n",
            "To: /content/dataset_nonrandom_responses.pth\n",
            "100%|██████████| 1.84G/1.84G [00:17<00:00, 108MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'cern_alice_fast_sim_corrvae'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 66 (delta 35), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (66/66), 30.88 KiB | 3.86 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "CONNECT WITH DRIVE\n",
        "\"\"\"\n",
        "\n",
        "%pip install gdown\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# url = 'https://drive.google.com/uc?id=1AvXhv8p9ZCUZ2dzbYoA5CP8VT7a8b6Gf' # full\n",
        "url = 'https://drive.google.com/uc?id=1Ay6j3rMwSq2qqBSCqC125tFG0c9MEXwW' # train\n",
        "\n",
        "output = 'dataset_nonrandom_responses.pth'\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Github\n",
        "!git clone https://github.com/karolrogozinski/cern_alice_fast_sim_corrvae.git\n",
        "\n",
        "source = '/content/cern_alice_fast_sim_corrvae'\n",
        "destination = '/content'\n",
        "\n",
        "for file in os.listdir(source):\n",
        "    source_path = os.path.join(source, file)\n",
        "    dest_path = os.path.join(destination, file)\n",
        "\n",
        "    try:\n",
        "        shutil.copy(source_path, dest_path)\n",
        "    except IsADirectoryError:\n",
        "        shutil.copytree(source_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Z7Wn5o68e7e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "CorrVAE training based on [TODO]\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import optim\n",
        "\n",
        "from model import ControlVAE\n",
        "from encoders import EncoderControlVAE\n",
        "from decoders import DecoderControlVAE\n",
        "\n",
        "from utils.helpers import plot_epoch, save_model\n",
        "from utils.loss import get_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jMjAHePO8e7f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "PROPERTIES\n",
        "All of them are normalized\n",
        "\n",
        "0. - x coordinate of max pixel\n",
        "1. - y coordinate of max pixel\n",
        "2. - x coordinate of mass center\n",
        "3. - y coordinate of mass center\n",
        "4. - number of non zero pixels\n",
        "5. - categorized number of non zero pixels\n",
        "6. - sum of pixels\n",
        "7. - max pixel value\n",
        "\"\"\"\n",
        "\n",
        "properties = [2, 3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nUgxkLxf8e7f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ARGUMENTS\n",
        "\"\"\"\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "results_dir = '/content/drive/MyDrive/models/'\n",
        "data_source = './data/dataset_nonrandom_responses_train.pth'\n",
        "\n",
        "img_size = (1, 44, 44)\n",
        "latent_dim = 8\n",
        "latent_dim_prop = 8\n",
        "latent_dim_cond = 9\n",
        "hid_channels = 32\n",
        "\n",
        "num_prop = len(properties)\n",
        "lr = 1e-4\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 250\n",
        "\n",
        "beta = 1\n",
        "taus = 0.2\n",
        "idx_kl = 0\n",
        "w_kl = 100\n",
        "\n",
        "lambdas = [\n",
        "    1000000,\n",
        "    5,\n",
        "    1000000,\n",
        "    5,\n",
        "    1\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO9lFgc8xuFX",
        "outputId": "681d9752-3f2d-4fd6-80b8-d1fb1c52d2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "WANDB LOGGER\n",
        "\"\"\"\n",
        "try:\n",
        "    import wandb\n",
        "except:\n",
        "    %pip install wandb\n",
        "    import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKzrL3-FxvNa",
        "outputId": "840f62bd-3669-49bd-f228-220de7b960b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key='a3dced463ecec1c51f36081c0e372206416cce0a', relogin=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "hLZtXjQo8e7g",
        "outputId": "5484efc9-1fd1-4d48-c0db-569a4e7950d9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'wandb' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/96/myqx4fm16sq0pxxklfdh9r8m0000gn/T/ipykernel_31860/3341763332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m wandb.init(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CorrVAE_64x64\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     config={\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# \"data size\": train_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
          ]
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=\"CorrVAE_64x64\",\n",
        "\n",
        "    config={\n",
        "        # \"data size\": train_size,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"beta\": beta,\n",
        "        \"taus\": taus,\n",
        "        \"loss func\": 'sigmoid',\n",
        "        \"lr\": lr,\n",
        "        \"num prop\": num_prop,\n",
        "        \"latent_dim\": latent_dim,\n",
        "        \"latent_dim_prop\": latent_dim_prop\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5LeeHiaG8e7h"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "DATA\n",
        "\"\"\"\n",
        "\n",
        "data = torch.load(data_source)\n",
        "dataset = TensorDataset(data['features'], data['labels'])\n",
        "\n",
        "train_loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RXM_59lV8e7h"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MODEL\n",
        "\"\"\"\n",
        "\n",
        "encoder = eval(\"EncoderControlVAE\")\n",
        "decoder = eval(\"DecoderControlVAE\")\n",
        "\n",
        "model = ControlVAE(img_size, encoder, decoder, latent_dim, latent_dim_prop, latent_dim_cond, num_prop, device=device)\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer,\n",
        "        milestones=[50, 100, 150, 200],\n",
        "        gamma=0.1\n",
        ")\n",
        "\n",
        "mse_loss = torch.nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "recon_loss_prop_rec = []\n",
        "recon_loss_rec = []\n",
        "kl_loss_rec = []\n",
        "pwwi_loss_rec = []\n",
        "pwz_loss_rec = []\n",
        "l1_loss_rec = []\n",
        "mask_rec = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "latent_dist_cond_mean = data['labels'][:, 9:].mean(axis=0)[0].to(device),\n",
        "latent_dist_cond_std = data['labels'][:, 9:].std(axis=0)[0].to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0015, -0.0040,  0.0015,  0.0097,  0.0004,  0.0017, -0.0026, -0.0023,\n",
              "        -0.0027])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "latent_dist_cond_mean[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_8TGUeB18e7i",
        "outputId": "3103279d-71ee-4404-ef1d-f986bc26c258"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3699 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'repeat'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/96/myqx4fm16sq0pxxklfdh9r8m0000gn/T/ipykernel_31860/71258018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         latent_dist_cond = (\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlatent_dist_cond_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mlatent_dist_cond_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'repeat'"
          ]
        }
      ],
      "source": [
        "start_epoch = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        taus = taus * 0.1\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_kl_loss = []\n",
        "    epoch_rec_loss = []\n",
        "    epoch_prop_loss = []\n",
        "    epoch_pairwise_loss = []\n",
        "    epoch_groupwise_loss = []\n",
        "    epoch_l1_norm = []\n",
        "\n",
        "    for (data, label) in tqdm(train_loader):\n",
        "        idx_kl += 1\n",
        "        data = data.to(device)\n",
        "        cond = label[:,9:].to(device)\n",
        "\n",
        "        latent_dist_cond = (\n",
        "            latent_dist_cond_mean.repeat(data.shape[0], 1),\n",
        "            latent_dist_cond_std.repeat(data.shape[0], 1)\n",
        "        )\n",
        "        latent_sample_cond = label[:, 9:].to(device)\n",
        "\n",
        "        (reconstruct,y_reconstruct), latent_dist_z, latent_dist_w,\\\n",
        "            latent_sample_z, latent_sample_w, w_mask, cond, mask_ori = model(data, cond, taus)\n",
        "\n",
        "        latent_sample = torch.cat([latent_sample_w, latent_sample_z], dim=-1)\n",
        "        latent_dist = (torch.cat([latent_dist_w[0], latent_dist_z[0]], dim=-1),\n",
        "                       torch.cat([latent_dist_w[1], latent_dist_z[1]], dim=-1))\n",
        "\n",
        "        ###### Reconstruction loss ######\n",
        "        rec_loss = F.mse_loss(reconstruct, data, reduction=\"sum\") / 64\n",
        "        rec_loss = rec_loss / batch_size\n",
        "\n",
        "        rec_loss_prop = []\n",
        "\n",
        "        for i, prop in enumerate(properties):\n",
        "            rec_loss_prop.append(mse_loss(y_reconstruct[:,i], label[:, prop].float().to(device)))\n",
        "\n",
        "        rec_loss_prop_all = sum(rec_loss_prop)\n",
        "\n",
        "        ###### Other losses ######\n",
        "        kl_loss, pairwise_tc_loss, groupwise_tc_loss, l1norm, loss, w_kl = get_losses(\n",
        "            latent_dist,\n",
        "            latent_sample_w,\n",
        "            latent_dist_w,\n",
        "            beta,\n",
        "            latent_sample_z,\n",
        "            latent_dist_z,\n",
        "            w_mask,\n",
        "            device,\n",
        "            idx_kl,\n",
        "            rec_loss,\n",
        "            rec_loss_prop_all,\n",
        "            w_kl,\n",
        "            len(train_loader.dataset),\n",
        "            lambdas,\n",
        "            latent_sample_cond,\n",
        "            latent_dist_cond\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss.append(float(loss))\n",
        "        epoch_kl_loss.append(float(kl_loss))\n",
        "        epoch_rec_loss.append(float(rec_loss))\n",
        "        epoch_prop_loss.append(float(rec_loss_prop_all))\n",
        "        epoch_pairwise_loss.append(float(pairwise_tc_loss))\n",
        "        epoch_groupwise_loss.append(float(groupwise_tc_loss))\n",
        "        epoch_l1_norm.append(float(l1norm))\n",
        "\n",
        "    wandb.log(\n",
        "        {\"total_loss \": np.mean(epoch_loss),\n",
        "            \"KL_loss\": np.mean(epoch_kl_loss),\n",
        "            \"rec_loss\": np.mean(epoch_rec_loss),\n",
        "            \"rec_prop_loss\": np.mean(epoch_prop_loss),\n",
        "            \"wwi_loss\": np.mean(epoch_pairwise_loss),\n",
        "            \"wz_loss\": np.mean(epoch_groupwise_loss),\n",
        "            \"l1_norm\": np.mean(epoch_l1_norm),\n",
        "    })\n",
        "\n",
        "    save_model(model, optimizer, results_dir, epoch)\n",
        "    plot_epoch(train_loader, model, device, taus, epoch, time.time() - start_epoch)\n",
        "\n",
        "    lr_scheduler.step()\n",
        "    start_epoch = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "75a7a2f2856d09d3581c769256ac1c015132059993c94c4aebdcd920fc505d70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
